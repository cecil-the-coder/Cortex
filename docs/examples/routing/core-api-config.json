{
  "server": {
    "host": "0.0.0.0",
    "port": 8080,
    "read_timeout": "60s",
    "write_timeout": "60s",
    "enable_cors": true,
    "cors_origins": ["*"]
  },
  "providers": [
    {
      "name": "openai",
      "auth_method": "api_key",
      "api_key": "${OPENAI_API_KEY}",
      "models": [
        "gpt-4",
        "gpt-4-turbo-preview",
        "gpt-4-1106-preview",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-16k"
      ],
      "base_url": "https://api.openai.com/v1"
    },
    {
      "name": "anthropic",
      "auth_method": "api_key",
      "api_key": "${ANTHROPIC_API_KEY}",
      "models": [
        "claude-3-opus-20240229",
        "claude-3-sonnet-20240229",
        "claude-3-haiku-20240307",
        "claude-2.1",
        "claude-2.0"
      ],
      "base_url": "https://api.anthropic.com"
    },
    {
      "name": "gemini",
      "auth_method": "api_key",
      "api_key": "${GEMINI_API_KEY}",
      "models": [
        "gemini-pro",
        "gemini-pro-vision"
      ],
      "base_url": "https://generativelanguage.googleapis.com/v1beta"
    },
    {
      "name": "azure-openai",
      "auth_method": "api_key",
      "api_key": "${AZURE_OPENAI_API_KEY}",
      "models": [
        "gpt-4",
        "gpt-4-32k",
        "gpt-35-turbo",
        "gpt-35-turbo-16k"
      ],
      "base_url": "https://your-resource.openai.azure.com",
      "metadata": {
        "api_version": "2023-12-01-preview",
        "deployment_id": "your-deployment"
      }
    },
    {
      "name": "openrouter",
      "auth_method": "api_key",
      "api_key": "${OPENROUTER_API_KEY}",
      "models": [
        "openai/gpt-4",
        "openai/gpt-3.5-turbo",
        "anthropic/claude-3-opus",
        "anthropic/claude-3-sonnet",
        "google/gemini-pro"
      ],
      "base_url": "https://openrouter.ai/api/v1"
    },
    {
      "name": "enterprise-openai",
      "auth_method": "oauth",
      "oauth": {
        "client_id": "${OPENAI_CLIENT_ID}",
        "client_secret": "${OPENAI_CLIENT_SECRET}",
        "token_url": "https://api.openai.com/oauth/token",
        "scopes": ["api:read", "api:write"],
        "grant_type": "client_credentials",
        "token_cache_duration": "1h"
      },
      "models": [
        "gpt-4",
        "gpt-4-turbo-preview"
      ],
      "base_url": "https://api.openai.com/v1"
    },
    {
      "name": "mistral",
      "auth_method": "api_key",
      "api_key": "${MISTRAL_API_KEY}",
      "models": [
        "mistral-large-latest",
        "mistral-medium-latest",
        "mistral-small-latest",
        "codestral-latest"
      ],
      "base_url": "https://api.mistral.ai/v1"
    }
  ],
  "health_monitoring": {
    "enabled": true,
    "check_interval": "30s",
    "timeout": "10s",
    "alert_threshold": 3,
    "parallel_checks": true,
    "status_change_callbacks": true,
    "metrics_collection": true,
    "log_level": "info"
  },
  "model_discovery": {
    "enabled": true,
    "cache_expiry": "5m",
    "parallel_discovery": true,
    "discovery_timeout": "30s",
    "include_inactive": false,
    "auto_refresh": true,
    "refresh_interval": "1h",
    "provider_specific_options": {
      "openai": {
        "include_pricing": true,
        "include_rate_limits": true
      },
      "anthropic": {
        "include_thinking_models": true,
        "include_beta_models": false
      }
    }
  },
  "request_conversion": {
    "default_model": "gpt-3.5-turbo",
    "max_tokens_limit": 128000,
    "strict_mode": false,
    "validation_rules": [
      "required_messages",
      "temperature_range",
      "max_tokens_positive",
      "tool_choice_consistency"
    ],
    "sanitization": {
      "enabled": true,
      "clamp_temperature": true,
      "clamp_max_tokens": true,
      "validate_json": true
    }
  },
  "response_conversion": {
    "enable_metadata": true,
    "preserve_provider_info": true,
    "fallback_on_error": true,
    "debug_mode": false,
    "supported_formats": [
      "legacy",
      "openai",
      "standard",
      "stream"
    ],
    "batch_conversion": {
      "enabled": true,
      "max_batch_size": 100,
      "parallel_conversion": true
    }
  },
  "routing": {
    "default_provider": "openai",
    "load_balancing": {
      "enabled": true,
      "strategy": "round_robin",
      "health_aware": true,
      "performance_weighted": false
    },
    "failover": {
      "enabled": true,
      "timeout": "10s",
      "retry_attempts": 3,
      "retry_delay": "1s",
      "exponential_backoff": true
    }
  },
  "rate_limiting": {
    "enabled": true,
    "requests_per_minute": 1000,
    "tokens_per_minute": 100000,
    "strategy": "sliding_window",
    "burst_size": 100
  },
  "logging": {
    "level": "info",
    "format": "json",
    "include_request_id": true,
    "include_provider": true,
    "include_timing": true,
    "structured": true
  },
  "metrics": {
    "enabled": true,
    "endpoint": "/metrics",
    "prometheus": true,
    "in_memory": true,
    "collection_interval": "10s"
  },
  "security": {
    "api_key_header": "X-API-Key",
    "enable_request_validation": true,
    "enable_response_validation": true,
    "max_request_size": "10MB",
    "max_response_size": "50MB",
    "allowed_origins": ["*"],
    "rate_limit_headers": true
  },
  "caching": {
    "enabled": false,
    "redis_url": "${REDIS_URL}",
    "ttl": "1h",
    "max_size": 1000,
    "key_prefix": "gollm:",
    "compress_responses": true
  },
  "admin": {
    "enabled": true,
    "username": "admin",
    "password_hash": "${ADMIN_PASSWORD_HASH}",
    "endpoints": {
      "health": "/admin/health",
      "metrics": "/admin/metrics",
      "config": "/admin/config",
      "providers": "/admin/providers",
      "models": "/admin/models",
      "reload": "/admin/reload"
    },
    "cors": {
      "enabled": true,
      "origins": ["http://localhost:3000", "https://admin.yourdomain.com"]
    }
  },
  "experimental": {
    "enable_core_api": true,
    "enable_provider_extensions": true,
    "enable_dynamic_providers": false,
    "streaming_optimizations": true,
    "zero_copy_conversions": false,
    "smart_routing": false,
    "predictive_health_checks": false
  },
  "feature_flags": {
    "anthropic_thinking_mode": true,
    "openai_json_mode": true,
    "azure_extensions": true,
    "tool_calling_standardization": true,
    "async_health_monitoring": true,
    "metrics_export": true,
    "debug_endpoints": false,
    "experimental_providers": false
  }
}